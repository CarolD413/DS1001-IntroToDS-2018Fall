{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Zhengyuan Ding\n",
    "\n",
    "Student Netid: zd415\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study (5 Points)\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input data and feature selection\n",
    "\n",
    "As mentioned in the article, Target collects a lot of data from their customers. Each customer is assigned with a unique Guest ID and this ID is linked with the individual's demographic information and shopping behaviors. The demongraphic information includes age, gender, marriage, born place, distance to the store etc. The shopping behavioral data include payment method, whether used a coupon, mail for refund etc. Some of them are numerical and others are categorical. \n",
    "\n",
    "First, we should do some feature selection to both reduce the data size and help prediction. We can calculate the information gain of each attributes and rank their informativeness. In particular, an entropy graph for each attribute could help us better understand the data. \n",
    "\n",
    "In addition to these processes, we can also generate some new features from our input data based on some exploratary analysis and our domain knowledge. For instance, we can check the stats summary of each variable and visualize its distribution as a histogram to find some possible insights.\n",
    "\n",
    "- Data preprocessing\n",
    "\n",
    "After feature selection, we should do some preprocessing on the dataset we selected. For instance, categorical data could be transformed by one-hot encoding and numerical data can be normalized to same range. For data cleaning, we can check for outliers and missing value. If they are missing at random, we could replace them with average or just delete them if it's rare.\n",
    "\n",
    "Also we should split the dataset to training, validation and test set.\n",
    "\n",
    "- Target value y \n",
    "\n",
    "The target value y we are predicting could be categorical with value 0 or 1 to classify if the customer is pregnant or not. \n",
    "\n",
    "- Training Model\n",
    "\n",
    "We could use SVM or decision tree to predict this classification problem. To avoid overfitting, we use a fitting curve with AUC on two datasets, training and validation set(or by cross-validation). If there is a large gap between the two curves, it shows a overfitting problem and we should tune the hyperparameters to control the complexity of the model.\n",
    "\n",
    "- Evaluation\n",
    "\n",
    "After tunning parameters in the training stage, we now come to the evaluation.\n",
    "First, the accuracy should be at least higher than the base rate.\n",
    "Second, we can compare the perfomance between the two models by generating ROC curves and computing AUC scores on the test set. The model with higher degree of bowing is likely to have better performance. Also we could use lift curve to check the performance as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line (4 Points)\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell on EC2 (see original directions) and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file? (look up 'wc' command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341 data/advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!wc -l \"data/advertising_events.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -d ',' -f 1 \"data/advertising_events.csv\"| sort -u | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114 google.com\r\n",
      "2092 facebook.com\r\n",
      "1036 youtube.com\r\n",
      "1034 yahoo.com\r\n",
      "1022 baidu.com\r\n",
      " 513 wikipedia.org\r\n",
      " 511 amazon.com\r\n",
      " 382 qq.com\r\n",
      " 321 twitter.com\r\n",
      " 316 taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -d ',' -f 3 \"data/advertising_events.csv\"|sort |uniq -c|sort -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "! grep -w 37 \"data/advertising_events.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically (16 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. (1 Point) Download the data set `\"data/ads_dataset.tsv\"` and load it into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code here\n",
    "import pandas as pd\n",
    "ads = pd.read_csv('data/ads_dataset.tsv',sep='\\t',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-101.1493</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     isbuyer  buy_freq  visit_freq  buy_interval  sv_interval  \\\n",
       "NaN        0       NaN           1           0.0          0.0   \n",
       "NaN        0       NaN           1           0.0          0.0   \n",
       "NaN        0       NaN           1           0.0          0.0   \n",
       "NaN        0       NaN           1           0.0          0.0   \n",
       "NaN        0       NaN           2           0.0          0.5   \n",
       "\n",
       "     expected_time_buy  expected_time_visit  last_buy  last_visit  \\\n",
       "NaN                0.0               0.0000       106         106   \n",
       "NaN                0.0               0.0000        72          72   \n",
       "NaN                0.0               0.0000         5           5   \n",
       "NaN                0.0               0.0000         6           6   \n",
       "NaN                0.0            -101.1493       101         101   \n",
       "\n",
       "     multiple_buy  multiple_visit  uniq_urls  num_checkins  y_buy  \n",
       "NaN             0               0        169          2130      0  \n",
       "NaN             0               0        154          1100      0  \n",
       "NaN             0               0          4            12      0  \n",
       "NaN             0               0        150           539      0  \n",
       "NaN             0               1        103           362      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. (4 Points) Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe().transpose()\n",
    "    output_data['number_nan']=input_data.isnull().sum()\n",
    "    output_data['number_distinct']=input_data.nunique(dropna=True)\n",
    "    return output_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `use %timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.7 ms ± 7.56 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. (2 Points) Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>1.240653</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>52257</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.852777</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.210008</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.62500</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>5.825610</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0</td>\n",
       "      <td>5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>-0.198040</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.28571</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-10.210786</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0</td>\n",
       "      <td>15135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.277444</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>86.569343</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>720.657592</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>127.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean          std       min    25%    50%  \\\n",
       "isbuyer                0.042632     0.202027    0.0000    0.0    0.0   \n",
       "buy_freq               1.240653     0.782228    1.0000    1.0    1.0   \n",
       "visit_freq             1.852777     2.921820    0.0000    1.0    1.0   \n",
       "buy_interval           0.210008     3.922016    0.0000    0.0    0.0   \n",
       "sv_interval            5.825610    17.595442    0.0000    0.0    0.0   \n",
       "expected_time_buy     -0.198040     4.997792 -181.9238    0.0    0.0   \n",
       "expected_time_visit  -10.210786    31.879722 -187.6156    0.0    0.0   \n",
       "last_buy              64.729335    53.476658    0.0000   18.0   51.0   \n",
       "last_visit            64.729335    53.476658    0.0000   18.0   51.0   \n",
       "multiple_buy           0.006357     0.079479    0.0000    0.0    0.0   \n",
       "multiple_visit         0.277444     0.447742    0.0000    0.0    0.0   \n",
       "uniq_urls             86.569343    61.969765   -1.0000   30.0   75.0   \n",
       "num_checkins         720.657592  1275.727306    1.0000  127.0  319.0   \n",
       "y_buy                  0.004635     0.067924    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      1.00000           0                2  \n",
       "buy_freq               1.000000     15.00000       52257               10  \n",
       "visit_freq             2.000000     84.00000           0               64  \n",
       "buy_interval           0.000000    174.62500           0              295  \n",
       "sv_interval            0.104167    184.91670           0             5886  \n",
       "expected_time_buy      0.000000     84.28571           0              348  \n",
       "expected_time_visit    0.000000     91.40192           0            15135  \n",
       "last_buy             105.000000    188.00000           0              189  \n",
       "last_visit           105.000000    188.00000           0              189  \n",
       "multiple_buy           0.000000      1.00000           0                2  \n",
       "multiple_visit         1.000000      1.00000           0                2  \n",
       "uniq_urls            155.000000    206.00000           0              207  \n",
       "num_checkins         802.000000  37091.00000           0             4628  \n",
       "y_buy                  0.000000      1.00000           0                2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Question4 Answer: The buy_freq variable contains a lot of missing values</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. (4 Points) For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be? Don't just show code here. Please explain your answer.\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0</td>\n",
       "      <td>13351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean          std       min    25%    50%  \\\n",
       "isbuyer                0.000000     0.000000    0.0000    0.0    0.0   \n",
       "buy_freq                    NaN          NaN       NaN    NaN    NaN   \n",
       "visit_freq             1.651549     2.147955    1.0000    1.0    1.0   \n",
       "buy_interval           0.000000     0.000000    0.0000    0.0    0.0   \n",
       "sv_interval            5.686388    17.623555    0.0000    0.0    0.0   \n",
       "expected_time_buy      0.000000     0.000000    0.0000    0.0    0.0   \n",
       "expected_time_visit   -9.669298    31.239030 -187.6156    0.0    0.0   \n",
       "last_buy              65.741317    53.484622    0.0000   19.0   52.0   \n",
       "last_visit            65.741317    53.484622    0.0000   19.0   52.0   \n",
       "multiple_buy           0.000000     0.000000    0.0000    0.0    0.0   \n",
       "multiple_visit         0.255602     0.436203    0.0000    0.0    0.0   \n",
       "uniq_urls             86.656180    61.996711   -1.0000   30.0   75.0   \n",
       "num_checkins         721.848518  1284.504018    1.0000  126.0  318.0   \n",
       "y_buy                  0.003024     0.054904    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      0.00000           0                1  \n",
       "buy_freq                    NaN          NaN       52257                0  \n",
       "visit_freq             2.000000     84.00000           0               48  \n",
       "buy_interval           0.000000      0.00000           0                1  \n",
       "sv_interval            0.041667    184.91670           0             5112  \n",
       "expected_time_buy      0.000000      0.00000           0                1  \n",
       "expected_time_visit    0.000000     91.40192           0            13351  \n",
       "last_buy             106.000000    188.00000           0              189  \n",
       "last_visit           106.000000    188.00000           0              189  \n",
       "multiple_buy           0.000000      0.00000           0                1  \n",
       "multiple_visit         1.000000      1.00000           0                2  \n",
       "uniq_urls            155.000000    206.00000           0              207  \n",
       "num_checkins         803.000000  37091.00000           0             4570  \n",
       "y_buy                  0.000000      1.00000           0                2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "nan_ads = ads[ads['buy_freq'].isnull()]\n",
    "getDfSummary(nan_ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Question5 answer: The missing value is not missing at random. isbuyer,buy_interval, expected_time_buy and multiple_buy variables all changes to 0,indicating that there is no purchase at all. Therefore the missing value should be zero</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. (4 Points) Which variables are binary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Question6 answer: isbuyer, multiple_buy, multiple_vist,y_buy </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
